{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import medfilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PIXELS = 16\n",
    "RADIUS = 300\n",
    "HORIZONTAL_BORDER = 30\n",
    "file_name = '../data/small-shaky-5.avi'\n",
    "cap = cv2.VideoCapture(file_name)\n",
    "frame_rate = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_transform(H, pt):\n",
    "    \"\"\"\n",
    "    @param: H is homography matrix of dimension (3x3) \n",
    "    @param: pt is the (x, y) point to be transformed\n",
    "    \n",
    "    Return:\n",
    "            returns a transformed point ptrans = H*pt.\n",
    "    \"\"\"\n",
    "    a = H[0,0]*pt[0] + H[0,1]*pt[1] + H[0,2]\n",
    "    b = H[1,0]*pt[0] + H[1,1]*pt[1] + H[1,2]\n",
    "    c = H[2,0]*pt[0] + H[2,1]*pt[1] + H[2,2]\n",
    "    return [a/c, b/c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def motion_propagate(old_points, new_points, old_frame):\n",
    "    \"\"\"\n",
    "    @param: old_points are points in old_frame that are \n",
    "            matched feature points with new_frame\n",
    "    @param: new_points are points in new_frame that are \n",
    "            matched feature points with old_frame\n",
    "    @param: old_frame is the frame to which \n",
    "            motion mesh needs to be obtained\n",
    "    @param: H is the homography between old and new points\n",
    "    \n",
    "    Return:\n",
    "            returns a motion mesh in x-direction \n",
    "            and y-direction for old_frame\n",
    "    \"\"\"\n",
    "    # spreads motion over the mesh for the old_frame\n",
    "    x_motion = {}; y_motion = {};\n",
    "    cols, rows = old_frame.shape[1]/PIXELS, old_frame.shape[0]/PIXELS\n",
    "    \n",
    "    # pre-warping with global homography\n",
    "    H, _ = cv2.findHomography(old_points, new_points, cv2.RANSAC)\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            pt = [PIXELS*j, PIXELS*i]\n",
    "            ptrans = point_transform(H, pt)\n",
    "            x_motion[i, j] = pt[0]-ptrans[0]\n",
    "            y_motion[i, j] = pt[1]-ptrans[1]\n",
    "            \n",
    "    # disturbute feature motion vectors\n",
    "    temp_x_motion = {}; temp_y_motion = {}\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            vertex = [PIXELS*j, PIXELS*i]\n",
    "            for pt, st in zip(old_points, new_points):\n",
    "                \n",
    "                # velocity = point - feature point match in next frame\n",
    "                # dst = sqrt((vertex[0]-st[0])**2+(vertex[1]-st[1])**2)\n",
    "                \n",
    "                # velocity = point - feature point in current frame\n",
    "                dst = np.sqrt((vertex[0]-pt[0])**2+(vertex[1]-pt[1])**2)\n",
    "                if dst < RADIUS:\n",
    "                    ptrans = point_transform(H, pt)\n",
    "                    try:\n",
    "                        temp_x_motion[i, j].append(st[0]-ptrans[0])\n",
    "                    except:\n",
    "                        temp_x_motion[i, j] = [st[0]-ptrans[0]]\n",
    "                    try:\n",
    "                        temp_y_motion[i, j].append(st[1]-ptrans[1])\n",
    "                    except:\n",
    "                        temp_y_motion[i, j] = [st[1]-ptrans[1]]\n",
    "    \n",
    "    # apply median filter (f-1) on obtained motion for each vertex\n",
    "    x_motion_mesh = np.zeros((rows, cols), dtype=float)\n",
    "    y_motion_mesh = np.zeros((rows, cols), dtype=float)\n",
    "    for key in x_motion.keys():\n",
    "        try:\n",
    "            temp_x_motion[key].sort()\n",
    "            x_motion_mesh[key] = x_motion[key]+temp_x_motion[key][len(temp_x_motion[key])/2]\n",
    "        except KeyError:\n",
    "            x_motion_mesh[key] = x_motion[key]\n",
    "        try:\n",
    "            temp_y_motion[key].sort()\n",
    "            y_motion_mesh[key] = y_motion[key]+temp_y_motion[key][len(temp_y_motion[key])/2]\n",
    "        except KeyError:\n",
    "            y_motion_mesh[key] = y_motion[key]\n",
    "    \n",
    "    # apply second median filter (f-2) over the motion mesh for outliers\n",
    "    x_motion_mesh = medfilt(x_motion_mesh, kernel_size=[3, 3])\n",
    "    y_motion_mesh = medfilt(y_motion_mesh, kernel_size=[3, 3])\n",
    "    \n",
    "    return x_motion_mesh, y_motion_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_vertex_profiles(x_paths, y_paths, x_motion_mesh, y_motion_mesh):\n",
    "    \"\"\"\n",
    "    @param: x_paths is vertex profiles along x-direction\n",
    "    @param: y_paths is vertex profiles along y_direction\n",
    "    @param: x_motion_mesh is obtained motion mesh along \n",
    "            x-direction from motion_propogate()\n",
    "    @param: y_motion_mesh is obtained motion mesh along \n",
    "            y-direction from motion_propogate()\n",
    "\n",
    "    Returns:\n",
    "            returns updated x_paths, y_paths with new \n",
    "            x_motion_mesh, y_motion_mesh added to the \n",
    "            last x_paths, y_paths\n",
    "    \"\"\"\n",
    "    new_x_path = x_paths[:, :, -1] + x_motion_mesh\n",
    "    new_y_path = y_paths[:, :, -1] + y_motion_mesh\n",
    "    x_paths = np.concatenate((x_paths, np.expand_dims(new_x_path, axis=2)), axis=2)\n",
    "    y_paths = np.concatenate((y_paths, np.expand_dims(new_y_path, axis=2)), axis=2)\n",
    "    return x_paths, y_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss(t, r, window_size):\n",
    "    \"\"\"\n",
    "    @param: window_size is the size of window over which gaussian to be applied\n",
    "    @param: t is the index of current point \n",
    "    @param: r is the index of point in window \n",
    "    \n",
    "    Return:\n",
    "            returns spacial guassian weights over a window size\n",
    "    \"\"\"\n",
    "    return np.exp((-9*(r-t)**2)/window_size**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_path(c, iterations=100, window_size=6):\n",
    "    \"\"\"\n",
    "    @param: c is original camera trajectory\n",
    "    @param: window_size is the hyper-parameter for the smoothness term\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "            returns an optimized gaussian smooth camera trajectory \n",
    "    \"\"\"\n",
    "    lambda_t = 100\n",
    "    p = np.empty_like(c)\n",
    "    \n",
    "    W = np.zeros((c.shape[2], c.shape[2]))\n",
    "    for t in range(W.shape[0]):\n",
    "        for r in range(-window_size/2, window_size/2+1):\n",
    "            if t+r < 0 or t+r >= W.shape[1] or r == 0:\n",
    "                continue\n",
    "            W[t, t+r] = gauss(t, t+r, window_size)\n",
    "\n",
    "    gamma = 1+lambda_t*np.dot(W, np.ones((c.shape[2],)))\n",
    "    \n",
    "    bar = tqdm(total=c.shape[0]*c.shape[1])\n",
    "    for i in range(c.shape[0]):\n",
    "        for j in range(c.shape[1]):\n",
    "            P = np.asarray(c[i, j, :])\n",
    "            for iteration in range(iterations):\n",
    "                P = np.divide(c[i, j, :]+lambda_t*np.dot(W, P), gamma)\n",
    "            p[i, j, :] = np.asarray(P)\n",
    "            bar.update(1)\n",
    "    \n",
    "    bar.close()\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mesh_warp_frame(frame, x_motion_mesh, y_motion_mesh):\n",
    "    \"\"\"\n",
    "    @param: frame is the current frame\n",
    "    @param: x_motion_mesh is the motion_mesh to \n",
    "            be warped on frame along x-direction\n",
    "    @param: y_motion_mesh is the motion mesh to \n",
    "            be warped on frame along y-direction\n",
    "\n",
    "    Returns:\n",
    "            returns a mesh warped frame according \n",
    "            to given motion meshes x_motion_mesh, \n",
    "            y_motion_mesh\n",
    "    \"\"\"\n",
    "    \n",
    "    # define handles on mesh in x-direction\n",
    "    map_x = np.zeros((frame.shape[0], frame.shape[1]), np.float32)\n",
    "    \n",
    "    # define handles on mesh in y-direction\n",
    "    map_y = np.zeros((frame.shape[0], frame.shape[1]), np.float32)\n",
    "    \n",
    "    for i in range(x_motion_mesh.shape[0]-1):\n",
    "        for j in range(x_motion_mesh.shape[1]-1):\n",
    "\n",
    "            src = [[j*PIXELS, i*PIXELS],\n",
    "                   [j*PIXELS, (i+1)*PIXELS],\n",
    "                   [(j+1)*PIXELS, i*PIXELS],\n",
    "                   [(j+1)*PIXELS, (i+1)*PIXELS]]\n",
    "            src = np.asarray(src)\n",
    "            \n",
    "            dst = [[j*PIXELS+x_motion_mesh[i, j], i*PIXELS+y_motion_mesh[i, j]],\n",
    "                   [j*PIXELS+x_motion_mesh[i+1, j], (i+1)*PIXELS+y_motion_mesh[i+1, j]],\n",
    "                   [(j+1)*PIXELS+x_motion_mesh[i, j+1], i*PIXELS+y_motion_mesh[i, j+1]],\n",
    "                   [(j+1)*PIXELS+x_motion_mesh[i+1, j+1], (i+1)*PIXELS+y_motion_mesh[i+1, j+1]]]\n",
    "            dst = np.asarray(dst)\n",
    "            H, _ = cv2.findHomography(src, dst, cv2.RANSAC)\n",
    "            \n",
    "            for k in range(PIXELS*i, PIXELS*(i+1)):\n",
    "                for l in range(PIXELS*j, PIXELS*(j+1)):\n",
    "                    x = H[0, 0]*l+H[0, 1]*k+H[0, 2]\n",
    "                    y = H[1, 0]*l+H[1, 1]*k+H[1, 2]\n",
    "                    w = H[2, 0]*l+H[2, 1]*k+H[2, 2]\n",
    "                    if not w == 0:\n",
    "                        x = x/(w*1.0); y = y/(w*1.0)\n",
    "                    else:\n",
    "                        x = l; y = k\n",
    "                    map_x[k, l] = x\n",
    "                    map_y[k, l] = y\n",
    "    \n",
    "    # repeat motion vectors for remaining frame in y-direction\n",
    "    for i in range(PIXELS*x_motion_mesh.shape[0], map_x.shape[0]):\n",
    "            map_x[i, :] = map_x[PIXELS*x_motion_mesh.shape[0]-1, :]\n",
    "            map_y[i, :] = map_y[PIXELS*x_motion_mesh.shape[0]-1, :]\n",
    "    \n",
    "    # repeat motion vectors for remaining frame in x-direction\n",
    "    for j in range(PIXELS*x_motion_mesh.shape[1], map_x.shape[1]):\n",
    "            map_x[:, j] = map_x[:, PIXELS*x_motion_mesh.shape[0]-1]\n",
    "            map_y[:, j] = map_y[:, PIXELS*x_motion_mesh.shape[0]-1]\n",
    "            \n",
    "    # deforms mesh\n",
    "    new_frame = cv2.remap(frame, map_x, map_y, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT)\n",
    "    return new_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time()    \n",
    "\n",
    "# generate stabilized video\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('../stable.avi', fourcc, frame_rate, (2*frame_width, frame_height))\n",
    "\n",
    "# params for ShiTomasi corner detection\n",
    "feature_params = dict( maxCorners = 1000,\n",
    "                    qualityLevel = 0.3,\n",
    "                    minDistance = 7,\n",
    "                    blockSize = 7 )\n",
    "\n",
    "# Parameters for lucas kanade optical flow\n",
    "lk_params = dict( winSize  = (15, 15),\n",
    "                maxLevel = 2,\n",
    "                criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 20, 0.03))\n",
    "\n",
    "# Take first frame\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "ret, old_frame = cap.read()\n",
    "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# preserve aspect ratio\n",
    "VERTICAL_BORDER = (HORIZONTAL_BORDER*old_gray.shape[1])/old_gray.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 209/210 [00:24<00:00,  8.28it/s]\n"
     ]
    }
   ],
   "source": [
    "# motion meshes in x-direction and y-direction\n",
    "x_motion_meshes = []; y_motion_meshes = []\n",
    "\n",
    "# path parameters\n",
    "x_paths = np.zeros((old_frame.shape[0]/PIXELS, old_frame.shape[1]/PIXELS, 1))\n",
    "y_paths = np.zeros((old_frame.shape[0]/PIXELS, old_frame.shape[1]/PIXELS, 1))\n",
    "\n",
    "frame_num = 1\n",
    "bar = tqdm(total=frame_count)\n",
    "while frame_num < frame_count:\n",
    "\n",
    "    # processing frames\n",
    "    ret, frame = cap.read()\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # find corners in it\n",
    "    p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n",
    "\n",
    "    # calculate optical flow\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "\n",
    "    # Select good points\n",
    "    good_new = p1[st==1]\n",
    "    good_old = p0[st==1]\n",
    "\n",
    "    # estimate motion mesh for old_frame\n",
    "    x_motion_mesh, y_motion_mesh = motion_propagate(good_old, good_new, frame)\n",
    "    try:\n",
    "        x_motion_meshes = np.concatenate((x_motion_meshes, np.expand_dims(x_motion_mesh, axis=2)), axis=2)\n",
    "        y_motion_meshes = np.concatenate((y_motion_meshes, np.expand_dims(y_motion_mesh, axis=2)), axis=2)\n",
    "    except:\n",
    "        x_motion_meshes = np.expand_dims(x_motion_mesh, axis=2)\n",
    "        y_motion_meshes = np.expand_dims(y_motion_mesh, axis=2)\n",
    "\n",
    "    # generate vertex profiles\n",
    "    x_paths, y_paths = generate_vertex_profiles(x_paths, y_paths, x_motion_mesh, y_motion_mesh)\n",
    "\n",
    "    # updates frames\n",
    "    bar.update(1)\n",
    "    frame_num += 1\n",
    "    old_frame = frame.copy()\n",
    "    old_gray = frame_gray.copy()\n",
    "\n",
    "bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 220/220 [00:01<00:00, 197.59it/s]\n",
      "100%|██████████| 220/220 [00:01<00:00, 127.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken:  2.94431400299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# optimize for smooth vertex profiles\n",
    "optimization = time()\n",
    "sx_paths = optimize_path(x_paths)\n",
    "sy_paths = optimize_path(y_paths)\n",
    "print 'Time Taken: ', time()-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fabb40c4290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot some vertex profiles\n",
    "for i in range(0, x_paths.shape[0]):\n",
    "    for j in range(0, x_paths.shape[1], 10):\n",
    "        plt.plot(x_paths[i, j, :])\n",
    "        plt.plot(sx_paths[i, j, :])\n",
    "        plt.savefig('../results/paths/'+str(i)+'_'+str(j)+'.png')\n",
    "        plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U = P-C\n",
    "x_motion_meshes = np.concatenate((x_motion_meshes, np.expand_dims(x_motion_meshes[:, :, -1], axis=2)), axis=2)\n",
    "y_motion_meshes = np.concatenate((y_motion_meshes, np.expand_dims(y_motion_meshes[:, :, -1], axis=2)), axis=2)\n",
    "new_x_motion_meshes = sx_paths-x_paths\n",
    "new_y_motion_meshes = sy_paths-y_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 210/210 [00:35<00:00,  6.14it/s]\n"
     ]
    }
   ],
   "source": [
    "r = 3\n",
    "frame_num = 0\n",
    "bar = tqdm(total=frame_count)\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "while frame_num < frame_count:\n",
    "    try:\n",
    "        # reconstruct from frames\n",
    "        ret, frame = cap.read()\n",
    "        x_motion_mesh = x_motion_meshes[:, :, frame_num]\n",
    "        y_motion_mesh = y_motion_meshes[:, :, frame_num]\n",
    "        new_x_motion_mesh = new_x_motion_meshes[:, :, frame_num]\n",
    "        new_y_motion_mesh = new_y_motion_meshes[:, :, frame_num]\n",
    "        \n",
    "        # mesh warping\n",
    "        new_frame = mesh_warp_frame(frame, new_x_motion_mesh, new_y_motion_mesh)\n",
    "        new_frame = new_frame[HORIZONTAL_BORDER:-HORIZONTAL_BORDER, VERTICAL_BORDER:-VERTICAL_BORDER, :]\n",
    "        new_frame = cv2.resize(new_frame, (frame.shape[1], frame.shape[0]), interpolation=cv2.INTER_CUBIC)\n",
    "        output = np.concatenate((frame, new_frame), axis=1)\n",
    "        out.write(output)\n",
    "\n",
    "        # draw old motion vectors\n",
    "        for i in range(x_motion_mesh.shape[0]):\n",
    "            for j in range(x_motion_mesh.shape[1]):\n",
    "                theta = np.arctan2(y_motion_mesh[i, j], x_motion_mesh[i, j])\n",
    "                cv2.line(frame, (j*PIXELS, i*PIXELS), (int(j*PIXELS+r*np.cos(theta)), int(i*PIXELS+r*np.sin(theta))), 1)\n",
    "        cv2.imwrite('../results/old_motion_vectors/'+str(frame_num)+'.jpg', frame)\n",
    "\n",
    "        # draw new motion vectors\n",
    "        for i in range(new_x_motion_mesh.shape[0]):\n",
    "            for j in range(new_x_motion_mesh.shape[1]):\n",
    "                theta = np.arctan2(new_y_motion_mesh[i, j], new_x_motion_mesh[i, j])\n",
    "                cv2.line(new_frame, (j*PIXELS, i*PIXELS), (int(j*PIXELS+r*np.cos(theta)), int(i*PIXELS+r*np.sin(theta))), 1)\n",
    "        cv2.imwrite('../results/new_motion_vectors/'+str(frame_num)+'.jpg', new_frame)\n",
    "\n",
    "        frame_num += 1\n",
    "        bar.update(1)\n",
    "    except:\n",
    "        break\n",
    "bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed:  118.327890873\n"
     ]
    }
   ],
   "source": [
    "cap.release()\n",
    "out.release()\n",
    "print 'Time elapsed: ', str(time()-start_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
